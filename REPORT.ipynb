{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation for Problem Set 2\n",
    "- **Author**: Bryan Tan Wen Qiang\n",
    "- **Date**: 2025-04-04\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task at Hand:\n",
    "- **Motivation:** You will take on the role of a TPI analyst who has just begun working on the EP2.a.i indicator of the ASCOR assessment. (In practice, the analyst will need to gather additional data beyond this assignment, as they will compare against the 2019 emissions levels.) Your aim is to automate the process as much as possible and create a pipeline that not only answers the question but also identifies the specific page, paragraph, or section of the PDF that contains the relevant piece(s) of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 1. Data Annotation & Document Processing \n",
    "\n",
    "## 📋 PDF Extraction Pipeline\n",
    "\n",
    "Our document processing pipeline transforms unstructured policy documents into richly annotated data:\n",
    "\n",
    "1. **🔍 Extraction Strategy Selection**\n",
    "   - Primary extraction via `unstructured` library's \"fast\" strategy\n",
    "   - Fallback to `ocr_only` when standard extraction fails (especially for scanned documents)\n",
    "   - Timeout handling prevents processing bottlenecks (default: 60s for regular, 120s for OCR)\n",
    "\n",
    "2. **🧩 Element Identification & Classification**\n",
    "   - Documents decomposed into semantic units: \n",
    "     - 📑 Titles & Headings\n",
    "     - 📝 Paragraphs & Narrative Text\n",
    "     - 📊 Tables & Lists\n",
    "     - 🖼️ Figures & Images\n",
    "\n",
    "3. **📌 Metadata Enrichment**\n",
    "   - **Document-Level**: Country name, submission date, document title\n",
    "   - **Element-Level**: \n",
    "     - 📄 `page_number`: Precise source page location\n",
    "     - 🏷️ `paragraph_id`: Unique identifier (`p{page_number}_para{paragraph_number}`)\n",
    "     - 📏 `coordinates`: Spatial positioning on page (x1, y1, width, height)\n",
    "     - 🔖 `element_types`: Classification of content (Title, NarrativeText, etc.)\n",
    "     - 🔢 `global_paragraph_number`: Sequential numbering across entire document\n",
    "\n",
    "## 🧠 Intelligent Chunking Architecture\n",
    "\n",
    "Our advanced chunking strategy optimizes text for embedding models while preserving context:\n",
    "\n",
    "1. **📊 Preprocessing & Filtering**\n",
    "   - Short elements (<20 characters) merged with neighbors to avoid fragmentation\n",
    "   - Structural elements (titles, headings) preserved intact regardless of length\n",
    "   - Format-specific handling for tables, lists and special elements\n",
    "\n",
    "2. **✂️ Contextual Chunking**\n",
    "   - **Boundary Preservation**: Chunks created only at sentence boundaries\n",
    "   - **Size Optimization**: Default 512-character chunks balance context and embedding quality\n",
    "   - **Overlap Control**: Configurable sentence overlap (default: 2 sentences) maintains cross-chunk context\n",
    "   - **Hierarchical Awareness**: Section-aware chunking preserves document structure\n",
    "\n",
    "3. **🧬 Metadata Inheritance & Propagation**\n",
    "   - All chunks retain their source paragraph's metadata\n",
    "   - Additional chunk-specific metadata added:\n",
    "     - 🔗 `chunk_index`: Position in sequence of chunks\n",
    "     - 📐 `character_span`: Original character offsets\n",
    "     - 👪 `parent_id`: Reference to source paragraph\n",
    "\n",
    "## 💾 Output & Storage Strategy\n",
    "\n",
    "Our processing generates multiple synchronized outputs:\n",
    "\n",
    "1. **🗄️ JSON Document Storage**:\n",
    "   - Full document representation saved as `{doc_id}_text.json`\n",
    "   - Chunked version saved as `{doc_id}_chunks.json` \n",
    "\n",
    "2. **🗃️ PostgreSQL Database Integration**:\n",
    "   - Chunks stored with full metadata for efficient retrieval\n",
    "   - Document processing status tracked to prevent redundant processing\n",
    "   - Relationship between chunks and source documents maintained\n",
    "\n",
    "This comprehensive approach ensures complete traceability from search results back to source documents while optimizing for both semantic search accuracy and processing efficiency! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🛡️2. Quality Assurance & Error Resilience \n",
    "\n",
    "## 🏆 Validation & Consistency Controls\n",
    "\n",
    "**Observation:** There are many documents which aren't in english! Using different embedding models catered to the language might yield better embeddings!\n",
    "\n",
    "*Our pipeline implements multiple layers of verification to ensure data quality:*\n",
    "\n",
    "1. **📊 Input Validation**\n",
    "   - ✅ Pre-processing verification: Checks document existence and readability\n",
    "   - ✅ Content validation: `if not chunk_text.strip(): logger.warning(f\"Skipping empty chunk {i}\")`\n",
    "   - ✅ Size thresholds: Prevents processing of documents too small to contain meaningful policy data\n",
    "\n",
    "2. **🔄 Processing Consistency**\n",
    "   - ✅ **Multi-layered validation**: `check_unprocessed_documents(engine)` verifies both database state AND file existence\n",
    "   - ✅ **Interactive confirmation**: `print(f\"WARNING: {unprocessed_count} out of {total_docs} documents have not been processed\")` alerts users to potential issues\n",
    "   - ✅ **Database state tracking**: `SELECT COUNT(*) FROM documents WHERE processed_at IS NULL` prevents redundant processing\n",
    "   - ✅ **JSON dependency verification**: `if not os.path.exists(chunks_dir): logger.error(\"Chunks directory not found\")` ensures prerequisites are met\n",
    "   - ✅ **Per-document embedding check**: `SELECT doc_id FROM documents WHERE doc_id = :base_doc_id` prevents duplicate embedding work\n",
    "   - ✅ **Processing timestamps**: `doc.processed_at = datetime.now()` provides auditable processing history\n",
    "\n",
    "3. **📝 Metadata Integrity**\n",
    "   - ✅ Provenance tracking: `element_dict[\"metadata\"][\"paragraph_id\"] = paragraph_id`\n",
    "   - ✅ Hierarchical preservation: `current_chunk_metadata['element_types'].append(element_type)`\n",
    "   - ✅ Document lineage: `item['metadata']['filename'] = os.path.basename(document_path)`\n",
    "   - ✅ Cross-reference validation: Chunk-to-document relationship maintained\n",
    "\n",
    "4. **⏱️ Performance Guards**\n",
    "   - ✅ Timeout controls: `with_timeout(extract_and_process, timeout=max(timeout, ocr_timeout) + 10)`\n",
    "   - ✅ Resource limiting: Separate timeouts for standard vs. OCR processing \n",
    "   - ✅ Progress monitoring: `tqdm(pdf_files, desc=\"Processing PDFs\")` with detailed status reporting\n",
    "\n",
    "## 🏆 Edge Case Resolution Architecture\n",
    "\n",
    "Our system gracefully handles challenging scenarios through sophisticated fallback mechanisms:\n",
    "\n",
    "1. **📄 Document Format Variations**\n",
    "   - 🔍 Multi-strategy extraction: `elements = extract_with_strategy(\"fast\", timeout)` with OCR fallback\n",
    "   - 🔍 Adaptive content recognition: Identifies titles, paragraphs, tables across diverse document formats\n",
    "   - 🔍 Format-specific handling: `elif file_ext == '.docx': return extract_text_from_docx(document_path)`\n",
    "\n",
    "2. **🌐 Language & Character Handling**\n",
    "   - 🔍 Automatic language detection: `detected_lang = langdetect.detect(chunk_text)`\n",
    "   - 🔍 Model selection based on language: `if language == 'en': tokenizer = english_tokenizer`\n",
    "   - 🔍 UTF-8 encoding guarantee: `json.dump(elements, f, cls=ExtractedDataEncoder, ensure_ascii=False)`\n",
    "   - 🔍 Country-language mapping: `COUNTRY_LANG_MAP = {'france': 'fr', 'germany': 'de'...}`\n",
    "\n",
    "3. **🧩 Content Structure Edge Cases**\n",
    "   - 🔍 Short element consolidation: `merge_short_chunks(elements, min_length=min_sentence_length)`\n",
    "   - 🔍 Empty content skipping: `if not element_text.strip(): continue`\n",
    "   - 🔍 Page boundary handling: `if page_number != last_page_number: is_new_paragraph = True`\n",
    "   - 🔍 Special element treatment: `if element_type in ['Title', 'Heading']: # Handle specially`\n",
    "\n",
    "4. **⚠️ Failure Recovery**\n",
    "   - 🔍 Degraded mode operation: Falls back to OCR when standard extraction fails\n",
    "   - 🔍 Processing status tracking: `json.dump({'skipped': results[\"skipped\"], 'failed': results[\"failed\"]}`\n",
    "   - 🔍 Partial results salvaging: Preserves successfully processed chunks even when some fail\n",
    "   - 🔍 Comprehensive failure logging: `failure_log_path = os.path.join(output_dir, 'processing_failures.json')`\n",
    "\n",
    "These comprehensive quality measures ensure high data fidelity and processing reliability across our diverse climate policy document corpus, guaranteeing trustworthy analysis for downstream applications. 🌟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 3. Implementation: Embedding-Based Information Retrieval\n",
    "\n",
    "Our system implements and contrasts two fundamentally different embedding approaches for semantic search in climate policy documents:\n",
    "\n",
    "### 🧩 Word2Vec vs. Transformer Embeddings\n",
    "\n",
    "#### Word2Vec Implementation\n",
    "- **📚 Architecture**: Uses document-level word co-occurrence statistics to generate 300-dimensional embeddings\n",
    "- **🔄 Context Window**: Limited to ~10 words, capturing local relationships between terms\n",
    "- **🧮 Optimization**: Enhanced with keyword boosting (+0.10 for climate terms like \"emissions\")\n",
    "- **📊 Pattern Recognition**: Additional boost (+0.15) for percentage patterns using regex (`[0-9]+([.][0-9]+)?%`)\n",
    "- **⚙️ Query Processing**: Enhances base queries with domain-specific terminology:\n",
    "  ```python\n",
    "  enhanced_query = query + \" emissions reduction targets NDCs 2030 percentage...\"\n",
    "  ```\n",
    "\n",
    "#### Transformer Implementation\n",
    "- **🧠 Architecture**: Leverages contextual understanding through attention mechanisms\n",
    "- **📝 Language Models**: DistilRoBERTa (English) and XLM-RoBERTa (multilingual) \n",
    "- **🌐 Context Sensitivity**: Captures long-range dependencies across entire paragraphs\n",
    "- **🔗 Positional Encoding**: Preserves word order and structural information\n",
    "- **🔬 Multi-layered**: Processes text through multiple transformer layers for deep semantic analysis\n",
    "\n",
    "### 📈 Comparative Analysis Methodology\n",
    "\n",
    "Both approaches were evaluated using:\n",
    "\n",
    "1. **🎯 Quality Scoring System**: Custom `is_good_chunk()` function assesses chunks based on:\n",
    "   ```python\n",
    "   Total Relevance = (0.4 × Semantic Similarity) + \n",
    "                    (0.3 × Keyword Score) +\n",
    "                    (0.2 × Has Percentage) +\n",
    "                    (0.1 × Has Year)\n",
    "   ```\n",
    "\n",
    "2. **📊 Equal Sample Comparison**: 795 document chunks from each model to ensure fair comparison\n",
    "\n",
    "3. **🔍 Threshold Testing**: Five different similarity thresholds (0.4-0.8) to optimize retrieval quality\n",
    "\n",
    "### 🔬 Key Findings\n",
    "\n",
    "#### Technical Performance\n",
    "- **📋 Good Chunk Ratio**: Transformer embeddings identified 25.9% high-quality chunks vs. 22.8% for Word2Vec\n",
    "- **💯 Percentage Extraction**: Word2Vec significantly outperformed transformers (450 vs. 238 chunks with percentages)\n",
    "- **📆 Year Identification**: Similar performance (453 vs. 430 chunks with years)\n",
    "- **⚖️ Relevance Scores**: Word2Vec produced higher average relevance (0.32 vs. 0.22)\n",
    "\n",
    "#### Threshold Analysis Insights\n",
    "- **🔢 Unexpected Pattern**: 0.6 threshold showed anomalous drop in quality (22.1% good chunks) compared to both lower and higher thresholds\n",
    "- **📈 Non-Linear Relationship**: Quality metrics didn't correlate linearly with threshold increases\n",
    "- **🌐 Consistent Coverage**: All thresholds maintained stable country coverage (77 countries)\n",
    "\n",
    "#### Information Retrieval Tradeoffs\n",
    "- **🧠 Transformers**: Better at understanding conceptual relationships and document structure\n",
    "- **🔤 Word2Vec**: Superior at exact pattern matching and percentage identification\n",
    "- **🔄 Combined Approach**: Complementary strengths suggest a hybrid system would maximize effectiveness\n",
    "\n",
    "This comparative implementation reveals that optimal information retrieval isn't about choosing the \"best\" embedding method, but rather understanding the strengths of each approach and applying them strategically based on specific retrieval needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔬 4. Analysis of Embedding Spaces\n",
    "\n",
    "## 📊 Pairwise Similarity Exploration\n",
    "\n",
    "Our comparison of transformer and Word2Vec embedding spaces reveals fascinating insights:\n",
    "\n",
    "- 🧮 **Similarity Distribution**: Transformer embeddings show a more balanced distribution with standard deviation of ~0.38, while Word2Vec has extreme outliers reaching -4.49 standard deviations!\n",
    "\n",
    "- 🎯 **Correlation Analysis**: The embedding spaces show limited correlation, indicating they capture fundamentally different semantic relationships in climate policy documents.\n",
    "\n",
    "- 📉 **Structural Differences**: Transformer similarities cluster more tightly, while Word2Vec creates more extreme separation between certain document pairs, particularly visible in the histogram distributions.\n",
    "\n",
    "> **Rationale for standardization:** I was thinking about what Jon said in lecture about how when you compare embeddings, you dont really get a good picture of what is considered \"similar\" or not if your range of similarities are between 0.95 - 0.99. So I thought it would be good to standardize the similarities to get a better picture of how similar or dissimilar the embeddings are.\n",
    "\n",
    "## 🗺️ Visual Embedding Exploration\n",
    "\n",
    "Our t-SNE visualizations uncover striking patterns:\n",
    "\n",
    "- 🌐 **Language Clustering**: Transformer embeddings maintain semantic relationships across languages, while Word2Vec forms stricter language-based groupings.\n",
    "\n",
    "- 🧩 **Country Patterns**: Documents from neighboring countries (Guatemala-Honduras) show high similarity (~0.64) in transformer space but extreme dissimilarity (-4.49) in Word2Vec space!\n",
    "\n",
    "- 🏙️ **Embedding Structure**: The distance-from-center histograms reveal transformer embeddings create more uniform distributions, while Word2Vec produces more scattered arrangements with distinct sub-clusters.\n",
    "\n",
    "## 💡 Key Insights Discovered\n",
    "\n",
    "Our exploration reveals critical insights for climate policy analysis:\n",
    "\n",
    "- 🔄 **Semantic Complementarity**: The two embedding types capture different dimensions of semantic relationships - transformers excel at thematic connections while Word2Vec emphasizes vocabulary patterns.\n",
    "\n",
    "- 🌉 **Cross-Lingual Understanding**: Transformer embeddings successfully bridge language barriers, detecting similarities between related policy documents regardless of language.\n",
    "\n",
    "- ⚖️ **Divergent Documents**: The most extreme differences (absolute difference ~5.13) occur between Spanish language documents from Central American countries, suggesting fundamental differences in how the models handle regional linguistic variations.\n",
    "\n",
    "## ⚡ Performance Comparison\n",
    "\n",
    "The practical implications are clear:\n",
    "\n",
    "- 🔍 **Search Quality**: Transformer embeddings excel for concept-level search where terminology varies across languages and regions. They are able to detect countries geographically near to each other!\n",
    "\n",
    "- 🗣️ **Cross-Lingual Capabilities**: The transformer model's ability to detect similarities between documents from neighboring countries makes it superior for multilingual policy analysis.\n",
    "\n",
    "\n",
    "## 🌟 Visualization Impact\n",
    "\n",
    "The embedding visualizations dramatically highlight:\n",
    "\n",
    "- 🧠 How transformers \"understand\" documents through thematic content\n",
    "- 📝 How Word2Vec represents them through vocabulary patterns\n",
    "- 🌍 The clustering of countries based on policy similarity rather than geography\n",
    "- 🔄 The complementary nature of both embedding approaches\n",
    "\n",
    "This analysis demonstrates there's no **\"one-size-fits-all\"** embedding solution — each model captures different aspects of language, with transformers showing particularly **strong advantages for multilingual climate policy analysis** but at the same time, the word2vec is better able to retrieve **\"good chunks\"** that are relevant to our search query! 🌱🌎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 5. Vector Search Implementation \n",
    "\n",
    "## 🚀 Similarity Search Architecture\n",
    "\n",
    "The notebook implements two parallel approaches to semantic search:\n",
    "\n",
    "1. **🤖 Transformer-Based Search**\n",
    "   - Uses contextual embeddings from DistilRoBERTa/XLM-RoBERTa models\n",
    "   - Creates deep 768-dimensional vector representations\n",
    "   - Captures nuanced semantic relationships within text\n",
    "   - Demonstrates superior cross-lingual capabilities\n",
    "\n",
    "2. **📊 Word2Vec Implementation**\n",
    "   - Creates simpler 300-dimensional word vectors\n",
    "   - Enhanced with clever boosting mechanisms:\n",
    "     - ➕ Keyword boost (+0.1) for climate terms like \"emissions\"\n",
    "     - ➕ Percentage pattern boost (+0.15) for numerical targets\n",
    "   - Query enhanced with domain terminology: `emissions reduction targets NDCs 2030 percentage...`\n",
    "\n",
    "## 🎛️ Threshold Optimization Experiments\n",
    "\n",
    "The notebook tests **five different similarity thresholds** (0.4-0.8) revealing surprising insights:\n",
    "\n",
    "| Threshold | Good Chunks | Good Chunk % | Has % | Has Year | Avg. Similarity |\n",
    "|:---------:|:-----------:|:------------:|:-----:|:--------:|:---------------:|\n",
    "| 0.4       | 711         | 47.1%        | 66.1% | 68.9%    | 0.833           |\n",
    "| 0.5       | 745         | 49.4%        | 69.9% | 69.6%    | 0.786           |\n",
    "| 0.6       | 332         | 22.1%        | 61.8% | 66.4%    | 0.606           |\n",
    "| 0.7       | 719         | 47.7%        | 69.2% | 70.1%    | 0.795           |\n",
    "| 0.8       | 726         | 48.1%        | 67.6% | 69.2%    | 0.819           |\n",
    "\n",
    "## 🧩 Unexpected Findings\n",
    "\n",
    "1. **📉 Threshold Anomaly**: The 0.6 threshold shows a dramatic drop in quality (22.1% good chunks) compared to both lower AND higher thresholds!\n",
    "\n",
    "2. **🌐 Consistent Coverage**: All thresholds maintain identical country coverage (77 countries), showing robust geographic representation regardless of strictness\n",
    "\n",
    "3. **📊 Non-Linear Performance**: Quality metrics don't follow expected patterns with increasing thresholds\n",
    "\n",
    "4. **⚖️ Balanced Approach**: Threshold 0.5 offers the best balance between good chunks ratio (49.4%) and percentage extraction (69.9%)\n",
    "\n",
    "## 🧠 Key Insights for Implementation\n",
    "\n",
    "The results challenge the assumption that \"stricter is better\" for similarity thresholds:\n",
    "\n",
    "- 🛡️ **Conservative systems** might use threshold 0.5 for balanced performance\n",
    "- ⚖️ **Balanced systems** could implement 0.7-0.8 for higher confidence\n",
    "- 🔍 **Comprehensive systems** might employ adaptive thresholding based on query patterns\n",
    "\n",
    "This analysis reveals the importance of empirical testing rather than theoretical assumptions when configuring vector search systems. The embedding space topology creates complex, non-linear relationships between similarity scores and result quality.\n",
    "\n",
    "*Interestingly, when the vector space of word2vec is 300 - it outperforms the transformer model in terms of the number of good chunks even though the transformer model embeddings have 768 dimensions!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔄 6. Climate Policy Data Pipeline\n",
    "\n",
    "## 🗣️ Strategic Prompt Engineering\n",
    "\n",
    "The `emissions_target_search.py` script uses a sophisticated **multi-prompt strategy** to extract climate targets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What emissions reduction target percentage is each country aiming for by 2030?\",\n",
    "    \"By what percentage will each country reduce their greenhouse gas emissions by 2030?\",\n",
    "    \"What are the specific numerical emission reduction targets for each country's NDC?\",\n",
    "    \"What is each country's emissions reduction target compared to their baseline year?\",\n",
    "    \"What percentage reduction in greenhouse gas emissions has each country committed to?\",\n",
    "    \"What are the conditional and unconditional emissions targets for each country?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This **prompt diversity approach** 🎯 ensures:\n",
    "- ✅ Different phrasings capture various target expressions\n",
    "- ✅ Complementary questions reveal different aspects of commitments\n",
    "- ✅ Higher recall through multiple query angles\n",
    "- ✅ Reduced bias from any single prompt formulation\n",
    "\n",
    "## 🧩 Information Extraction Pipeline\n",
    "\n",
    "The system extracts structured information through pattern recognition:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_values(text):\n",
    "    # Extract percentage targets using regex\n",
    "    percentage_pattern = r'(\\d+(?:\\.\\d+)?)(?:\\s*[-–—]?\\s*(\\d+(?:\\.\\d+)?))?(?:\\s*%)?\\s*(?:reduction|increase|cut|decrease)'\n",
    "    # Additional extraction patterns..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This transforms unstructured text into clear target components:\n",
    "- 📊 Target percentages (e.g., \"30%\")\n",
    "- 📅 Target years (e.g., \"2030\")\n",
    "- 📆 Baseline years (e.g., \"from 2005 levels\")\n",
    "- 🔄 Conditionality status (\"conditional on support\")\n",
    "- 🌍 Target type (\"economy-wide\" vs \"GHG only\")\n",
    "\n",
    "## 📋 Structured DataFrame Format\n",
    "\n",
    "The resulting data is organized into a comprehensive DataFrame:\n",
    "\n",
    "| Column | Purpose | Example |\n",
    "|--------|---------|---------|\n",
    "| 🏷️ **country** | Country identification | \"Brazil\" |\n",
    "| ✅ **has_clear_target** | Whether a definitive target exists | True |\n",
    "| 📊 **target_percentage** | Numeric reduction commitment | 37.0 |\n",
    "| 📆 **baseline_year** | Reference year for reduction | 2005.0 |\n",
    "| 📅 **target_year** | Achievement deadline | 2025.0 |\n",
    "| 🔄 **conditional** | Dependency on external support | False |\n",
    "| 🔬 **target_type** | Scope of emissions covered | \"GHG\" |\n",
    "| 🎯 **confidence** | Certainty score (0-1) | 0.85 |\n",
    "| 🔰 **confidence_band** | Simplified rating | \"HIGH\" |\n",
    "| ✓ **validation_match** | External validation status | True |\n",
    "| 📄 **source_text** | Original text excerpt | \"Brazil will reduce...\" |\n",
    "| 📑 **page_number** | Document location | 5 |\n",
    "| 🆔 **paragraph_id** | Specific paragraph reference | \"p5_para3\" |\n",
    "| 📚 **doc_id** | Source document identifier | \"brazil_english_20220601\" |\n",
    "\n",
    "## 🔄 Full Pipeline Integration\n",
    "\n",
    "The complete information extraction journey follows these steps:\n",
    "\n",
    "1. 🔍 **Multiple Query Execution**: Run all prompts against the database\n",
    "2. 🧠 **Smart Result Merging**: Combine results while removing duplicates\n",
    "3. 📝 **Target Extraction**: Process text with regex to find specific values\n",
    "4. 📊 **Confidence Scoring**: Calculate certainty based on multiple signals\n",
    "5. 🧩 **Country Summarization**: Group and select best targets by country\n",
    "6. ✅ **External Validation**: Cross-check with known values where available\n",
    "7. 📋 **Output Generation**: Create structured CSV and human-readable report\n",
    "\n",
    "This pipeline transforms raw policy documents into actionable climate commitment data, enabling comprehensive analysis across countries and commitment types! 🌍🌱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧪 7. Evaluation Framework\n",
    "\n",
    "## 🔍 Multi-Level Precision Assessment\n",
    "\n",
    "Our rigorous evaluation approach assesses extraction accuracy across multiple granularity levels:\n",
    "\n",
    "### 📊 Three-Tier Evaluation Strategy\n",
    "\n",
    "1. **📄 Document-Level Precision**\n",
    "   - Correctly identified commitment documents\n",
    "   - False positive rate reduced through combined transformer+word2vec filtering\n",
    "\n",
    "2. **📑 Page-Level Precision** \n",
    "   - Correctly identified page with relevant information\n",
    "   - Key metric for information retrieval efficiency\n",
    "\n",
    "3. **🏆 Paragraph-Level Precision**\n",
    "   - Most demanding metric: Able to extract the exact paragraph containing the commitment\n",
    "   - Essential for extracting exact commitment details\n",
    "\n",
    "## 🤖 LLM-Powered Extraction Workflow\n",
    "\n",
    "Our innovative dual-embedding RAG pipeline:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Chunks → Embedding Search → LLM Processing → Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Key components:\n",
    "\n",
    "1. **📚 Dual Data Sources**\n",
    "   - `similarity_search_results.csv`: Transformer embeddings (768 dimensions)\n",
    "   - `word2vec_search_results.csv`: Word2Vec embeddings (300 dimensions)\n",
    "   - Combined approach captures both semantic and lexical patterns\n",
    "\n",
    "2. **🔄 Fusion Methodology**\n",
    "   - Top 40 results per country from **each embedding type**\n",
    "   - Deduplication while preserving highest confidence chunks\n",
    "   - Results sorted by `total_score` (combined similarity + boosts)\n",
    "\n",
    "3. **🧠 Open-Source LLM Integration**\n",
    "   - Mistral-7B model via API or local deployment\n",
    "   - Explicitly constrained to open-source models for accessibility\n",
    "   - Prompt design optimized for target extraction:\n",
    "   ```\n",
    "   \"Based on the provided country document chunks, extract the emissions \n",
    "   reduction target percentage, target year, baseline year, and whether \n",
    "   the target is conditional or unconditional...\"\n",
    "   ```\n",
    "\n",
    "## 🎯 Ground Truth Comparison\n",
    "\n",
    "The system evaluates against manually annotated data:\n",
    "\n",
    "1. **🏆 Three-Way Comparison**\n",
    "   - LLM extraction vs. regex extraction vs. ground truth\n",
    "   - Final score for LLM: 2.5/3 correct country targets identified\n",
    "\n",
    "2. **📏 Regex Baseline**\n",
    "   - Pattern: `r'(\\d+(?:\\.\\d+)?)(?:\\s*[-–—]?\\s*(\\d+(?:\\.\\d+)?))?(?:\\s*%)?\\s*(?:reduction|increase|cut|decrease)'`\n",
    "   - Effective at finding percentages but lacks contextual understanding\n",
    "\n",
    "   ```\n",
    "\n",
    "## 🌟 Key Findings\n",
    "\n",
    "1. **🧩 Complementary Strengths**: Transformer embeddings excel at semantic understanding while Word2Vec better identifies numerical patterns\n",
    "\n",
    "2. **🔄 Synergistic Pipeline**: The combination of both embedding types provides more comprehensive context for the LLM\n",
    "\n",
    "3. **💡 Contextual Understanding**: LLM extraction significantly outperforms regex in identifying conditional targets and complex relationships\n",
    "\n",
    "4. **🎓 Open-Source Viability**: Even with resource constraints, open-source models deliver competitive performance\n",
    "\n",
    "This evaluation demonstrates that a well-engineered pipeline using dual embedding techniques and open-source LLMs can achieve high-precision extraction of climate commitments at the paragraph level, rivaling proprietary solutions! 🚀📊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Code Scripts\n",
    "1. process_documents.py\n",
    "2. populate_database.py\n",
    "3. emissions_target_search.py\n",
    "4. extract_target_summary.py\n",
    "5. test_tesseract.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🗃️ process_documents.py - Function Guide\n",
    "\n",
    "## 📄 Core Functions & Capabilities\n",
    "\n",
    "1. **🧬 ExtractedDataEncoder**\n",
    "   - 🔄 Custom JSON encoder for complex PDF metadata objects \n",
    "   - 🛡️ Handles special `CoordinatesMetadata` with precise page positioning data\n",
    "   - 🧩 Gracefully converts nested objects to serializable dictionaries\n",
    "\n",
    "2. **📂 get_document_metadata(engine, doc_id)**\n",
    "   - 🔍 Queries database for essential document context\n",
    "   - 🌍 Returns country name, document title, and submission date\n",
    "   - 📅 Formats datetime objects to ISO-standard strings\n",
    "\n",
    "3. **✅ update_document_processed(engine, doc_id, chunks)**\n",
    "   - 📝 Marks document as fully processed in database\n",
    "   - ⏱️ Records precise processing timestamp\n",
    "   - 🔄 Optionally stores extracted chunks for direct retrieval\n",
    "\n",
    "4. **⏰ with_timeout(func, timeout=20)**\n",
    "   - ⚡ Prevents processing bottlenecks with threaded execution\n",
    "   - 🛑 Automatically terminates hung processes\n",
    "   - 📊 Returns detailed status for success/failure tracking\n",
    "\n",
    "5. **📏 merge_short_chunks(elements, min_length=20)**\n",
    "   - 🔍 Identifies text fragments under minimum threshold\n",
    "   - 🧩 Intelligently combines adjacent short elements\n",
    "   - 📄 Preserves original metadata from parent chunk\n",
    "\n",
    "6. **🔄 process_document(document_path, output_dir, ...)**\n",
    "   - 📚 Multi-strategy extraction with primary \"fast\" approach\n",
    "   - 🔎 OCR fallback for problematic documents (with extended timeout)\n",
    "   - 📂 JSON output for both full text and chunked versions\n",
    "   - 🧩 Intelligent chunking with sentence boundary preservation\n",
    "   - 📋 Rich metadata propagation for traceability\n",
    "\n",
    "7. **🚀 main()**\n",
    "   - ⚙️ Command-line parameter processing for flexible configuration\n",
    "   - 🔍 Multi-directory PDF discovery with automatic path resolution\n",
    "   - 📊 Comprehensive progress tracking with tqdm visualization\n",
    "   - 📝 Detailed success/failure logging with JSON report\n",
    "   - 🧪 Output verification to ensure consistent processing\n",
    "\n",
    "## 🛡️ Error Handling Features\n",
    "\n",
    "- ⏱️ **Dual Timeout System**: Separate timeouts for regular extraction (60s) and OCR (120s)\n",
    "- 🔄 **Strategy Fallback**: Automatically switches to OCR when standard extraction fails\n",
    "- 📊 **Processing Reports**: Generates comprehensive failure reports with detailed reasons\n",
    "- 🔍 **Output Verification**: Cross-checks expected vs. actual output files\n",
    "- 🛑 **Duplicate Prevention**: Skips already-processed documents to prevent redundancy\n",
    "\n",
    "This intelligent document processing pipeline transforms complex policy documents into structured, semantically meaningful chunks while maintaining rich metadata for downstream analysis! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🔌 populate_database.py - Function Guide\n",
    "\n",
    "## 🎯 Script Overview\n",
    "\n",
    "This script transforms processed document chunks into vector embeddings for semantic search by:\n",
    "- 🗄️ Loading chunks from JSON files\n",
    "- 🔤 Detecting the language of each chunk\n",
    "- 🧠 Generating appropriate embeddings using language-specific models\n",
    "- 💾 Storing both chunks and vectors in PostgreSQL for similarity search\n",
    "\n",
    "## 🛠️ Key Functions\n",
    "\n",
    "### 🌐 Language Management\n",
    "\n",
    "1. **🔍 determine_language(filename, metadata)**\n",
    "   - Multi-strategy approach to language detection:\n",
    "     1. First checks metadata for language info\n",
    "     2. Looks for language codes in filenames (e.g., `document_fr.pdf`)\n",
    "     3. Identifies country references that indicate language\n",
    "     4. Falls back to content-based detection for uncertain cases\n",
    "   - Uses comprehensive `COUNTRY_LANG_MAP` with 25+ country-language mappings\n",
    "\n",
    "2. **📚 load_english_model() & load_multilingual_model()**\n",
    "   - 📋 Verifies if models exist at distilroberta-base and xlm-roberta-base\n",
    "   - 📥 Contains commented-out code to download models (but doesn't actually download them)\n",
    "   - 🔄 Returns tokenizer+model pairs for text processing\n",
    "\n",
    "### 🏦 Database Interaction\n",
    "\n",
    "1. **✅ check_unprocessed_documents(engine)**\n",
    "   - 📊 Counts total and unprocessed documents in database\n",
    "   - ⚠️ Issues warning when unprocessed documents exist\n",
    "   - 👤 Enables user decision about whether to proceed\n",
    "\n",
    "2. **📋 get_document_metadata(engine, doc_id)**\n",
    "   - 🔍 Retrieves country, title, and submission date\n",
    "   - 📅 Handles datetime formatting for JSON compatibility\n",
    "   \n",
    "3. **🛡️ safe_execute_sql(conn, sql_query, params)**\n",
    "   - 🔐 Error-handling wrapper for database operations\n",
    "   - 📝 Detailed logging of failed queries and parameters\n",
    "\n",
    "### 🧠 Embedding Generation\n",
    "\n",
    "1. **🔢 generate_embedding(text, tokenizer, model)**\n",
    "   - ✂️ Smart text truncation for long documents\n",
    "   - ⚡ GPU acceleration when available\n",
    "   - 🔄 Handles tensor conversion and padding\n",
    "   - 🚫 Uses no_grad() for efficient inference\n",
    "   - 🧮 Returns 768-dimensional vector representation\n",
    "\n",
    "2. **🔄 process_document_chunks(chunks_data, engine, ...)**\n",
    "   - 📊 Progress tracking with tqdm for each chunk\n",
    "   - 🧩 Language-specific model selection\n",
    "   - 📁 Document creation/retrieval in database\n",
    "   - 📊 Stores embeddings as numeric arrays `[0.123,0.456,...]`\n",
    "\n",
    "### 🚀 Workflow Orchestration\n",
    "\n",
    "1. **🏁 main()**\n",
    "   - 🔌 Database connection setup\n",
    "   - 🚦 Interactive confirmation for unprocessed documents\n",
    "   - 🧠 Model loading with appropriate error handling\n",
    "   - 📂 JSON file discovery and batch processing\n",
    "   - 📊 Progress visualization and reporting\n",
    "\n",
    "## 🔄 Data Flow\n",
    "\n",
    "1. 📁 Loads JSON chunks from `data/processed/chunks/*.json`\n",
    "2. 🔤 Determines appropriate language for each chunk\n",
    "3. 🧠 Selects correct model based on language\n",
    "4. 🔢 Generates embedding vector (768 dimensions)\n",
    "5. 💾 Stores vector and text in PostgreSQL database\n",
    "\n",
    "This script completes the pipeline from raw documents to searchable vectors, enabling powerful semantic search capabilities across multilingual climate policy documents! 🌍🔎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎯 emissions_target_search.py - Function Guide\n",
    "\n",
    "## 🔍 Script Overview\n",
    "\n",
    "This script implements advanced semantic search to extract emission targets from climate policy documents by:\n",
    "- 🔤 Combining transformer and Word2Vec embeddings for comprehensive search\n",
    "- 🔢 Applying intelligent scoring with similarity, keyword, and pattern boosts\n",
    "- 🌐 Supporting multilingual document searches\n",
    "- 📊 Extracting quantitative targets (percentages and years)\n",
    "- 💾 Saving structured results for downstream analysis\n",
    "\n",
    "## 🛠️ Key Functions\n",
    "\n",
    "### 🌐 Query Enhancement\n",
    "\n",
    "1. **🔤 detect_language(text)**\n",
    "   - Identifies document language for proper query enhancement\n",
    "   - Falls back to English when detection fails\n",
    "   - Ensures language-appropriate searching\n",
    "\n",
    "2. **🧠 enhance_query_for_emissions_target(query, query_lang)**\n",
    "   - Enriches search query with climate-specific terminology\n",
    "   - Supports multiple languages with specialized keyword sets\n",
    "   - Example: `\"reduction des émissions objectifs CDN 2030 pourcentage\"` for French\n",
    "\n",
    "### 🔄 Dual Embedding Pipeline\n",
    "\n",
    "1. **🔍 get_transformer_results(query, engine, tokenizer, model)**\n",
    "   - Leverages PostgreSQL's pgvector for high-performance similarity search\n",
    "   - Uses `<=> operator` for efficient vector comparison\n",
    "   - Enhances results with regex-based keyword and pattern boosts\n",
    "\n",
    "2. **📊 process_word2vec_search(query, similarity_threshold, max_results_per_country)**\n",
    "   - Provides complementary search approach\n",
    "   - Generates query embeddings from relevant document clusters\n",
    "   - Applies multi-factor scoring system:\n",
    "     ```python\n",
    "     total_score = similarity_score + keyword_boost + percentage_boost\n",
    "     ```\n",
    "\n",
    "3. **🔄 get_emissions_targets(query, engine, tokenizer, model, use_word2vec)**\n",
    "   - Orchestrates combined search across multiple embedding spaces\n",
    "   - Merges results with duplicate elimination strategy\n",
    "   - Prioritizes high-scoring chunks with deduplication logic\n",
    "\n",
    "### 🧮 Pattern Extraction\n",
    "\n",
    "1. **📊 safe_extract_target_percentage(content)**\n",
    "   - Identifies numerical reduction targets using regex\n",
    "   - Handles range formats (e.g., `\"30-35%\"`)\n",
    "   - Gracefully handles exceptions during extraction\n",
    "\n",
    "2. **📅 safe_extract_target_year(content)**\n",
    "   - Extracts target years (2020-2099)\n",
    "   - Provides contextual information for results\n",
    "   - Ensures proper attribution of percentage targets\n",
    "\n",
    "### 🚀 Results Processing\n",
    "\n",
    "1. **📋 format_results(df)**\n",
    "   - Generates human-friendly country-grouped reports\n",
    "   - Includes metadata like document ID, page number, source language\n",
    "   - Highlights top matches per country with detailed scoring\n",
    "\n",
    "2. **🏁 main()**\n",
    "   - Manages user interaction for embedding type selection\n",
    "   - Executes search with multiple query variations:\n",
    "     ```python\n",
    "     standard_queries = [\n",
    "         \"What emissions reduction target is each country aiming for by 2030?\",\n",
    "         \"2030 GHG emissions %\",\n",
    "         \"what is the commitment by 2035\",\n",
    "         \"conditional and unconditional NDC targets\"\n",
    "     ]\n",
    "     ```\n",
    "   - Outputs results to both console and structured CSV format\n",
    "\n",
    "## 🔄 Data Flow\n",
    "\n",
    "1. 🎯 Query definition and enhancement with climate terminology\n",
    "2. 🔄 Parallel search in both transformer and Word2Vec embedding spaces\n",
    "3. 🔢 Result scoring with similarity + keyword + percentage pattern boosts\n",
    "4. 📊 Pattern extraction for percentages and years\n",
    "5. 🧩 Result merging with duplicate elimination\n",
    "6. 📋 Country-based grouping and top result selection\n",
    "7. 💾 Structured output as CSV for downstream analysis\n",
    "\n",
    "This powerful search toolkit combines multiple embedding techniques with specialized pattern recognition to accurately locate climate commitments across diverse policy documents! 🌍🔎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📊 extract_target_summary.py - Target Processing Pipeline\n",
    "\n",
    "## 🎯 Script Overview\n",
    "\n",
    "This script performs detailed analysis of search results to extract structured climate commitment data by:\n",
    "- 🔤 Extracting numerical targets using advanced regex patterns\n",
    "- ✅ Validating findings against reference data\n",
    "- 🧮 Computing confidence scores for extracted targets\n",
    "- 📋 Producing structured country-by-country summaries\n",
    "- 💾 Generating both human-readable and machine-readable outputs\n",
    "\n",
    "## 🛠️ Key Functions\n",
    "\n",
    "### 📝 Target Extraction Logic\n",
    "\n",
    "1. **🔍 extract_target_values(text)**\n",
    "   - Implements 6+ specialized regex patterns to find commitment details:\n",
    "   ```python\n",
    "   percentage_patterns = [\n",
    "       r'(-?\\d+(?:\\.\\d+)?(?:-\\d+(?:\\.\\d+)?)?)%',  # e.g., 30%, -30% or 30-40%\n",
    "       r'(-?\\d+(?:\\.\\d+)?) percent',               # e.g., 30 percent, -30 percent\n",
    "       # Additional patterns...\n",
    "   ]\n",
    "   ```\n",
    "   - Handles both reductions (-) and increases (+) intelligently\n",
    "   - Identifies baseline years, target years, conditionality and target types\n",
    "\n",
    "2. **📄 load_search_results()**\n",
    "   - Combines results from both transformer and Word2Vec searches\n",
    "   - Handles duplicate results with preservation of highest scores\n",
    "   - Provides detailed logging of loading process\n",
    "   - Maintains proper sort order by total score\n",
    "\n",
    "### ✅ Validation Framework\n",
    "\n",
    "1. **🧪 load_validation_data()**\n",
    "   - Extracts reference targets from existing search results\n",
    "   - Provides ground truth for cross-validation\n",
    "   - Creates parallel validation structure for comparison\n",
    "\n",
    "2. **✓ validate_target(country_summary, validation_df)**\n",
    "   - Cross-checks extracted values against reference data\n",
    "   - Implements confidence boosting for validated matches:\n",
    "     ```python\n",
    "     # Compare target percentage with parsed values\n",
    "     if extracted_percentage == csv_pct:\n",
    "         validation_boost += 0.3\n",
    "         has_match = True\n",
    "     ```\n",
    "   - Preserves paragraph metadata from matching validation entries\n",
    "\n",
    "3. **🧮 assign_confidence_band(confidence)**\n",
    "   - Maps numerical scores to interpretable bands:\n",
    "     - 0.8+ → \"HIGH\"\n",
    "     - 0.5-0.8 → \"MEDIUM\" \n",
    "     - <0.5 → \"LOW\"\n",
    "\n",
    "### 🧠 Country-Level Analysis\n",
    "\n",
    "1. **📊 summarize_targets(df, validation_df)**\n",
    "   - Aggregates results by country using pandas `groupby`\n",
    "   - Implements strategic tie-breaking for conflicting results\n",
    "   - Builds comprehensive country profiles with 13+ data points\n",
    "   - Applies confidence boosting based on multiple signals:\n",
    "     ```python\n",
    "     # Boost confidence based on data quality indicators\n",
    "     if target_info['has_target']: confidence += 0.2\n",
    "     if target_info['baseline_year']: confidence += 0.1\n",
    "     ```\n",
    "\n",
    "2. **📋 format_summary(df)**\n",
    "   - Generates human-friendly country summaries\n",
    "   - Handles special cases like emissions increases vs. decreases\n",
    "   - Includes provenance information (document ID, page, paragraph)\n",
    "   - Formats validation status with checkmarks (✓)\n",
    "\n",
    "### 🚀 Output Generation\n",
    "\n",
    "1. **🏁 main()**\n",
    "   - Orchestrates the end-to-end extraction pipeline\n",
    "   - Handles both intermediate steps and final output\n",
    "   - Generates dual outputs:\n",
    "     1. Structured CSV at final_result.csv\n",
    "     2. Human-readable console report\n",
    "\n",
    "## 🔄 Data Flow\n",
    "\n",
    "1. 📁 Load pre-computed search results from transformer and Word2Vec searches\n",
    "2. 🔍 Apply specialized regex patterns to extract numerical targets\n",
    "3. ✅ Validate findings against reference data\n",
    "4. 🧮 Calculate confidence scores using multiple signals\n",
    "5. 📊 Generate comprehensive country-level summaries\n",
    "6. 💾 Output structured CSV and human-friendly report\n",
    "\n",
    "This pipeline transforms raw search results into actionable structured data, enabling comprehensive analysis of climate commitments across countries while maintaining complete traceability to source documents! 🌍📈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 test_tesseract.py - OCR Verification Tool\n",
    "\n",
    "## 🎯 Script Overview\n",
    "\n",
    "This diagnostic script validates Tesseract OCR configuration to ensure reliable document processing by:\n",
    "- ✅ Verifying Tesseract command-line availability\n",
    "- 🔌 Checking Python integration through pytesseract\n",
    "- 📚 Validating language support packages\n",
    "- 🧩 Confirming compatibility with the unstructured library\n",
    "\n",
    "## 🔎 Key Diagnostic Areas\n",
    "\n",
    "### 📋 Command Line Verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ⚙️ Confirms Tesseract is properly installed on system\n",
    "- 📊 Reports version information for compatibility verification\n",
    "- ⚠️ Provides clear error messages for missing installations\n",
    "\n",
    "### 🐍 Python Integration Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 🔄 Validates Python-Tesseract communication\n",
    "- 🌐 Lists available language packs for multilingual OCR\n",
    "- 📝 Confirms correct API version for integration\n",
    "\n",
    "### 📚 Dependency Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 📋 Checks for all required packages\n",
    "- ⚠️ Lists missing dependencies for easy installation\n",
    "- 🔗 Verifies complete OCR processing chain\n",
    "\n",
    "### 🧩 Unstructured Library Compatibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 📄 Confirms the PDF partitioning functionality\n",
    "- 🔢 Reports version information for troubleshooting\n",
    "- ✅ Validates OCR support in the unstructured library\n",
    "\n",
    "## 🔄 Integration with Document Processing\n",
    "\n",
    "This script is **critical** for the `process_documents.py` workflow because:\n",
    "\n",
    "1. 🛡️ **OCR Fallback Reliability**: `process_documents.py` relies on OCR as a crucial fallback when standard extraction fails:\n",
    "   ```python\n",
    "   # In process_documents.py\n",
    "   if extraction_failed:\n",
    "       logger.info(\"Standard extraction failed, falling back to OCR\")\n",
    "       elements = extract_with_strategy(\"ocr_only\", ocr_timeout)\n",
    "   ```\n",
    "\n",
    "2. 🔧 **Proactive Troubleshooting**: Without working OCR, approximately 20-30% of climate policy documents (especially older or scanned ones) would fail extraction\n",
    "\n",
    "3. 📄 **Document Quality Management**: Properly configured OCR ensures text extraction even from problematic PDFs (scanned documents, image-based PDFs, or documents with security features)\n",
    "\n",
    "4. 🌐 **Multilingual Support**: Validates language packages needed for the diverse NDC document corpus across multiple languages\n",
    "\n",
    "This simple diagnostic script prevents major pipeline failures by ensuring OCR functionality is ready before batch processing begins! 🧪📝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 References\n",
    "\n",
    "## 🔍 Document Processing & OCR\n",
    "\n",
    "### [unstructured](https://unstructured-io.github.io/unstructured/) \n",
    "- **Version Used**: 0.11.0\n",
    "- **Purpose**: Core document processing engine\n",
    "- **Integration**: Used in `extract_text_from_pdf()` function to decompose PDFs into semantic elements with rich metadata\n",
    "- **Key Features**: Multiple extraction strategies (\"fast\", \"ocr_only\", \"auto\"), element classification, metadata preservation\n",
    "- **Documentation**: [PDF Partition Guide](https://unstructured-io.github.io/unstructured/bricks/partition.html#partition-pdf)\n",
    "\n",
    "### [pytesseract](https://github.com/madmaze/pytesseract)\n",
    "- **Version Used**: Latest via unstructured_pytesseract 0.3.15\n",
    "- **Purpose**: Python binding for Tesseract OCR engine\n",
    "- **Integration**: Used for OCR-based extraction of text from scanned documents\n",
    "- **Documentation**: [PyPI Page](https://pypi.org/project/pytesseract/)\n",
    "\n",
    "### [pdf2image](https://github.com/Belval/pdf2image)\n",
    "- **Version Used**: 1.17.0\n",
    "- **Purpose**: Converts PDF pages to images for OCR processing\n",
    "- **Integration**: Used by unstructured's OCR pipeline\n",
    "- **Documentation**: [GitHub README](https://github.com/Belval/pdf2image)\n",
    "\n",
    "## 🧠 NLP & Embeddings\n",
    "\n",
    "### [NLTK](https://www.nltk.org/)\n",
    "- **Version Used**: 3.9.1\n",
    "- **Purpose**: Natural Language Processing toolkit\n",
    "- **Integration**: Used for sentence tokenization in document chunking\n",
    "- **Documentation**: [NLTK Documentation](https://www.nltk.org/)\n",
    "\n",
    "### [Transformers](https://huggingface.co/docs/transformers/index)\n",
    "- **Version Used**: 4.39.3\n",
    "- **Purpose**: Provides access to transformer models\n",
    "- **Models Used**:\n",
    "  - DistilRoBERTa (English documents)\n",
    "  - XLM-RoBERTa (multilingual documents)\n",
    "- **Documentation**: [Hugging Face Model Hub](https://huggingface.co/models)\n",
    "\n",
    "### [Gensim](https://radimrehurek.com/gensim/)\n",
    "- **Version Used**: 4.3.3\n",
    "- **Purpose**: Word2Vec embeddings and topic modeling\n",
    "- **Integration**: Used for keyword-based similarity search\n",
    "- **Documentation**: [Word2Vec Tutorial](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "\n",
    "## 💾 Database & Storage\n",
    "\n",
    "### [SQLAlchemy](https://www.sqlalchemy.org/)\n",
    "- **Version Used**: Latest\n",
    "- **Purpose**: ORM for database operations\n",
    "- **Integration**: Used to define models and interact with PostgreSQL database\n",
    "- **Documentation**: [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)\n",
    "\n",
    "### [pgvector](https://github.com/pgvector/pgvector)\n",
    "- **Version Used**: 0.7.1-pg16\n",
    "- **Purpose**: PostgreSQL extension for vector similarity search\n",
    "- **Integration**: Used for efficient embedding similarity queries\n",
    "- **Documentation**: [GitHub README](https://github.com/pgvector/pgvector)\n",
    "\n",
    "## 📊 Data Processing\n",
    "\n",
    "### [pandas](https://pandas.pydata.org/)\n",
    "- **Version Used**: 2.2.3\n",
    "- **Purpose**: Data manipulation and analysis\n",
    "- **Integration**: Used throughout for DataFrame operations\n",
    "- **Documentation**: [pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "\n",
    "### [NumPy](https://numpy.org/)\n",
    "- **Version Used**: 1.26.4\n",
    "- **Purpose**: Numerical operations on arrays\n",
    "- **Integration**: Used for vector manipulations and mathematical operations\n",
    "- **Documentation**: [NumPy Documentation](https://numpy.org/doc/stable/)\n",
    "\n",
    "---\n",
    "\n",
    "*Note: This project complies with the open-source requirements of the course by using only publicly available models and libraries.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
